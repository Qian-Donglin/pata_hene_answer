- [Pythonで記述されたバージョン](#pythonで記述されたバージョン)
- [C言語で書きなおして、O3オプションでコンパイル](#c言語で書きなおしてo3オプションでコンパイル)
- [命令の並列性](#命令の並列性)
	- [ループ展開の利用](#ループ展開の利用)
	- [これらのテクでなんで早くなる？](#これらのテクでなんで早くなる)
- [ブロッキング](#ブロッキング)
- [複数のプロセッサによる並列化](#複数のプロセッサによる並列化)

# Pythonで記述されたバージョン

```py3
for i in range(n): 
	for j in range(n): 
		for k in range(n): 
			C[i][j] += A[i][k] * B[k][j]
```

Pythonはインタプリンタ言語なので、コンパイラによる全体に亘っての構文最適化は行われない。ゆえに、このままでは非常に遅い。

# C言語で書きなおして、O3オプションでコンパイル

```cpp
void mul(int n, double *A, double *B, double *C){
	for(int i = 0; i < n; i++){
		for(int j = 0; j < n; j++){
			double a = A[i * n + j];//A[i][j]
			for(int k = 0; k < n; k++){
				a += B[i * n + k] * C[k * n + j];//B[i][k] * C[k][j]
			}
			A[i * n + j] = a;//こうすることで愚直に毎回A[i * n + j]からロードしなくて済む。
		}
	}
}
```

これは全体に亘った構文最適化がコンパイラでよってされるからかなり早くなる。例えば、添え字の計算は毎回プラス1して、doubleのサイズ2バイトぶんをかけるのではなく、アドレスベースで毎回2バイトぶんずつ、足していくのである。

# 命令の並列性

パイプラインで実行される命令にとって、**依存関係がない命令同士は並列実行できる=部分語並列性**。
これを意図的に意識させるテクとして、**まとめてロード**である。

また、レジスタが潤沢にあるなら、**データハザード解消のために真依存以外をレジスタの内容をコピーしてから命令を並べ替えるレジスタリネーミングで解決できる**。

このように、パイプライン実行を考慮した時の、命令レベルの並列性を考慮するともっと早くなる。
「アセンブリとしても乗算した値を足す」というステップは不要。

さらに、8個の倍精度浮動小数点をいっきりにロードして演算する、命令の並列性を利用したソースコードになっている。

```cpp
for(int i = 0; i < n; i += 8){
	for(int j = 0; j < n; j++){
		__m512d c0 = _mm512_load_pd(C + i * n + j); //倍精度の浮動小数点8個という型　　メモリから明示的にC[i][j]をロード
		for(int k = 0; k < n; k++){
			//c0 += A[i][k] * B[k][j]
			__m512d bb = _mm512_broadcastsd_pd(_mm_load_sd(B + j * n + k)); //B[k][j]を8つ分コピーする。
			c0 = _m512_fmadd_pd(_mm512_loadpd(A + n * k + i), bb, c0); //8つの積の計算は並列可能
			//上の乗算命令は並列して乗算、加算できるので、「アセンブリとしても乗算した値を足す」というステップは不要。
		}
		_m512_store_pd(C + i + j * n, c0); // C[i][j] = c0;
	}
}
```

## ループ展開の利用

小さいループを見つけた時、意図的に展開していくつかの文が並んでいる状態にすることを＝ループ展開(Loop Unrolling)という。
ここでは、前は8つのロードを一気にやっていたが、今回は1回のループあたり32個をロードすることになり、外のループの刻みが荒い代わりに、
ループ内でロードは4つ並んで記述することにした(ループで書いてあるけどコンパイル時は4つ順番に並んでいる)。

実際、このループ展開によって、最適化されたO3オプションでは11行を4回繰り返すはずが、20行となっている。
ソースコード内ではループを回しているが、4階しか回さないことを明示してる以上、コンパイラが自動でループ展開したプログラムしてくれる。

```cpp
const int UNROLL = 4;

for(int i = 0; i < n; i += UNROLL * 8){
	for(int j = 0; j < n; j++){
		__m512d c[UNROLL];
		for(int r = 0; r < UNROLL; r++){
			c[r] = _mm512_load_pd(C + i * n + j + r * 8); //メモリから連続したC[i][j]をUNROLL個ロードする。
		}
		__m512d c0 = _mm512_load_pd(C + i * n + j); //倍精度の浮動小数点8個という型　　メモリから明示的にC[i][j]をロード
		for(int k = 0; k < n; k++){
			//c0 += A[i][k] * B[k][j]
			__m512d bb = _mm512_broadcastsd_pd(_mm_load_sd(B + j * n + k)); //B[k][j]を8つ分コピーする。
			c0 = _m512_fmadd_pd(_mm512_loadpd(A + n * k + i), bb, c0); //8つの積の計算は並列可能
		}
		_m512_store_@d(C + i * n + j, c0); // C[i][j] = c0;
	}
}
```

## これらのテクでなんで早くなる？

パイプライン実行を考慮した時の、命令レベルの並列性を考慮するともっと早くなる。
また、ループ展開によって、ループにかかるオーバーヘッドが減るので早くなる。

# ブロッキング

キャッシュメモリに可能ならばちょうど入るサイズで作業したい。**行列には小行列に分けて計算しても同じ答えが得られるというすばらしい性質があるため、キャッシュメモリに収まるサイズで小行列の積を計算すればよい**。この手法は**ブロッキング**といい、そのサイズをブロッキングサイズという。

```cpp
void mul(int n, double *A, double *B, double *C){
	for(int i = 0; i < n; i++){//行
		for(int j = 0; j < n; j++){//列
			double a = A[i * n + j];//A[i][j]
			for(int k = 0; k < n; k++){ //積の計算のためのイテレーション
				a += B[i * n + k] * C[k * n + j];//B[i][k] * C[k][j]
			}
			A[i * n + j] = a;//こうすることで愚直に毎回A[i * n + j]からロードしなくて済む。
		}
	}
}
```

これを

```cpp
const int BLOCK_SIZE = 32;

void do_block(int n, int si, int sj, int sk, double *A, double *B, double *C){
	for(int i = si; i < si + BLOCK_SIZE; i++){ //行
		for(int j = sj; j < sj + BLOCK_SIZE; j++){ //列
			double aij = A[i * n + j];//A[i][j]
			for(int k = sk; k < sk + BLOCK_SIZE; k+){
				aij += B[i * n + k] * C[k * n + j]; //B[i][k] * C[k][j]
			}
			A[i * n + j] = aij;
		}
	}
}

void mul(int n, double *A, double *B, double *C){
	for(int si = 0; si < n; si += BLOCK_SIZE){
		for(int sj = 0; sj < n; sj += BLOCK_SIZE){
			for(int sk = 0; sk < n; sk += BLOCK_SIZE){
				do_block(n, si, sj, sk, A, B, C);
			}
		}
	}
}
```

# 複数のプロセッサによる並列化

ソースコードの中で、ライブラリを使用して明示的に並列的な実行を要求することとなる。C言語での並列プログラミングライブラリOpenMPを使おう。

```cpp
#include <x86intrin.h>

//ブロック化された行列計算関数mul()で次の部分を付け加える。
void mul(int n, double *A, double *B, double *C){
	#pragma omp parallel for //これを追加することで、勝手にスレッド数に応じた並列実行を最適化できる。
	for(int si = 0; si < n; si += BLOCK_SIZE){
		for(int sj = 0; sj < n; sj += BLOCK_SIZE){
			for(int sk = 0; sk < n; sk += BLOCK_SIZE){
				do_block(n, si, sj, sk, A, B, C);
			}
		}
	}
}

```

なお、OpenMPを使わない場合、**回すコンピュータのスレッド数を理解して**、そこで人力でプロセッサごとの行列のループ範囲の割り当てを行う必要がある。

| 名称           | Lv  | 職業       | 筋力 | 耐久 | 器用 | 感覚 | 習得 | 意志 | 魔力 | 魅力 | 速度 | 技能等                         |
| -------------- | --- | ---------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ------------------------------ |
| レッドドラゴン | 40  | プレデター | 129  | 175  | 101  | 63   | 71   | 63   | 99   | 63   | 144  | 火炎放射、火炎に素晴らしい耐性 |